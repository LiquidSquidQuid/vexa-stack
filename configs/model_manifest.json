{
  "google_drive": {
    "enabled": true,
    "folder_id": "1HvM1aNyjj7kh1LXZFH7zbqF_o2cdKY_L",
    "folder_url": "https://drive.google.com/drive/folders/1HvM1aNyjj7kh1LXZFH7zbqF_o2cdKY_L",
    "auto_sync": true,
    "description": "All files in this folder are automatically downloaded and sorted by type"
  },
  "models": [
    {
      "type": "checkpoint",
      "name": "RealVisXL_V5.0_Lightning_fp16.safetensors",
      "url": "https://huggingface.co/SG161222/RealVisXL_V5.0_Lightning/resolve/main/RealVisXL_V5.0_Lightning_fp16.safetensors",
      "source": "huggingface",
      "size": "6.46GB",
      "description": "Primary base model for Vexa - photorealistic SDXL model",
      "required": true
    },
    {
      "type": "lora",
      "name": "add-detail-xl.safetensors",
      "url": "https://huggingface.co/LyliaEngine/add-detail-xl/resolve/main/add-detail-xl.safetensors",
      "source": "huggingface",
      "size": "49.6MB",
      "description": "Enhances fine details in generated images (use weight 1.5, range -3 to 3)",
      "required": true
    },
    {
      "type": "vae",
      "name": "sdxl_vae.safetensors",
      "url": "https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors",
      "source": "huggingface",
      "size": "334.6MB",
      "description": "SDXL VAE for better color reproduction",
      "required": true
    },
    {
      "type": "embedding",
      "name": "negativeXL_D.safetensors",
      "url": "https://civitai.com/api/download/models/263032",
      "source": "civitai",
      "size": "1KB",
      "description": "Negative embedding for SDXL",
      "required": false
    },
    {
      "type": "upscale",
      "name": "RealESRGAN_x4plus.pth",
      "url": "https://huggingface.co/fofr/comfyui/resolve/main/upscale_models/RealESRGAN_x4plus.pth",
      "source": "huggingface",
      "size": "63.9MB",
      "description": "4x upscaler for high-res outputs",
      "required": true
    },
    {
      "type": "upscale",
      "name": "RealESRGAN_x2.pth",
      "url": "https://huggingface.co/fofr/comfyui/resolve/main/upscale_models/RealESRGAN_x2.pth",
      "source": "huggingface",
      "size": "64MB",
      "description": "2x upscaler for moderate upscaling",
      "required": false
    },
    {
      "type": "diffusion_model",
      "name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "source": "huggingface",
      "size": "14GB",
      "description": "Wan 2.2 I2V High-Noise Model (first pass) for image-to-video",
      "required": true,
      "category": "i2v"
    },
    {
      "type": "diffusion_model",
      "name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "source": "huggingface",
      "size": "14GB",
      "description": "Wan 2.2 I2V Low-Noise Model (refine pass) for image-to-video",
      "required": true,
      "category": "i2v"
    },
    {
      "type": "vae",
      "name": "wan_2.1_vae.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
      "source": "huggingface",
      "size": "335MB",
      "description": "Wan VAE for video generation",
      "required": true,
      "category": "i2v"
    },
    {
      "type": "text_encoder",
      "name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "source": "huggingface",
      "size": "5GB",
      "description": "UMT5 XXL text encoder for Wan video models",
      "required": true,
      "category": "i2v"
    },
    {
      "type": "clip_vision",
      "name": "clip_vision_h.safetensors",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors",
      "source": "huggingface",
      "size": "2GB",
      "description": "CLIP Vision H for image encoding in Wan I2V",
      "required": true,
      "category": "i2v"
    }
  ],
  "file_routing": {
    "description": "How files are automatically sorted based on filename patterns",
    "rules": [
      {"pattern": "*lora*, *LoRA*", "destination": "models/loras/"},
      {"pattern": "*vae*, *VAE*", "destination": "models/vae/"},
      {"pattern": "*embedding*, *embed*", "destination": "models/embeddings/"},
      {"pattern": "*upscale*, *ESRGAN*, *4x*, *2x*", "destination": "models/upscale_models/"},
      {"pattern": "*controlnet*, *cn_*", "destination": "models/controlnet/"},
      {"pattern": "*clip_vision*", "destination": "models/clip_vision/"},
      {"pattern": "*umt5*, *t5xxl*, *text_encoder*", "destination": "models/text_encoders/"},
      {"pattern": "*diffusion*, *i2v*, *wan*", "destination": "models/diffusion_models/"},
      {"pattern": "*clip*", "destination": "models/clip/"},
      {"pattern": "*.json", "destination": "user/default/workflows/"},
      {"pattern": "*.safetensors, *.ckpt", "destination": "models/checkpoints/"}
    ]
  },
  "download_settings": {
    "parallel_downloads": 2,
    "retry_attempts": 3,
    "retry_delay_seconds": 30,
    "timeout_seconds": 3600
  }
}
